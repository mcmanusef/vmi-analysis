#! /bin/env python3

import sys
import math
import argparse

import h5py
import numpy as np

BLOCK_SIZE = int(1e6)

parser = argparse.ArgumentParser(prog='tpx-stat', description="Show general information about the Timepix 3 data that can be computed quickly. \
Only a few MB of the data is considered.")
parser.add_argument('hdf_file')
args = parser.parse_args()

f = h5py.File(args.hdf_file, "r")

frame = f["frame_number"]
toa = f["toa"]
tdc_times = f["tdc_time"]
tdc_types = f["tdc_type"]

hits = len(toa)


print('Hits:\t\t', hits)

if hits != 0:
    last_toa = toa[-1]
    print(f'Last TOA:\t {last_toa * 1e-12:.5f} s')

    # last_toa is in ps
    print(f'MHits/s:\t {hits / last_toa * 1e6:.4f}')

middle = len(tdc_times) // 2

tdc_times_subset = tdc_times[:BLOCK_SIZE]
tdc_types_subset = tdc_types[:BLOCK_SIZE]

tdc_1_rising = tdc_types_subset == 1
tdc_1_falling = tdc_types_subset == 2
tdc_2_rising = tdc_types_subset == 3
tdc_2_falling = tdc_types_subset == 4


def compute_tdc_frequency(indices):
    first = np.min(tdc_times_subset[indices])
    last = np.max(tdc_times_subset[indices])
     
    return len(indices) / ((last - first) * 1e-12)

print('-'*30)

print('TDC 1:\t\t', 'YES' if np.any(tdc_1_rising) or np.any(tdc_1_falling) else 'NO')

if np.any(tdc_1_rising):
    print(f'TDC 1 rising:\t {compute_tdc_frequency(tdc_1_rising):.0f} Hz')
if np.any(tdc_1_falling):
    print(f'TDC 1 falling:\t {compute_tdc_frequency(tdc_1_falling):.0f} Hz')

print('TDC 2:\t\t', 'YES' if np.any(tdc_2_rising) or np.any(tdc_2_falling) else 'NO')

if np.any(tdc_2_rising):
    print(f'TDC 2 rising:\t {compute_tdc_frequency(tdc_2_rising):.0f} Hz')
if np.any(tdc_2_falling):
    print(f'TDC 2 rising:\t {compute_tdc_frequency(tdc_2_falling):.0f} Hz')

print('-'*30)

clustered = 'cluster_index' in f
print('Clustered:\t', 'YES' if clustered else 'NO')

if clustered:
    max_cluster_index = np.max(f['cluster_index'][-BLOCK_SIZE:])
    print('Clusters:\t', max_cluster_index + 1) # + 1 since clusters start from zero
    
    if hits:
        cluster_size = hits / max_cluster_index

        print(f'Hits/clusters:\t {cluster_size:.1f}')


     




